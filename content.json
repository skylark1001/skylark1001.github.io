{"meta":{"title":"还没想好的名字","subtitle":"","description":"","author":"Wang","url":"https://skylark1001.github.io","root":"/"},"pages":[{"title":"所有分类","date":"2020-05-18T16:45:26.303Z","updated":"2020-05-18T16:45:26.303Z","comments":true,"path":"categories/index.html","permalink":"https://skylark1001.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-05-18T16:44:18.755Z","updated":"2020-05-18T16:44:18.755Z","comments":true,"path":"about/index.html","permalink":"https://skylark1001.github.io/about/index.html","excerpt":"","text":"测试"},{"title":"所有标签","date":"2020-05-18T16:46:16.247Z","updated":"2020-05-18T16:46:16.247Z","comments":true,"path":"tags/index.html","permalink":"https://skylark1001.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ClassicConvNet","slug":"ClassicConvNet","date":"2020-08-04T14:20:02.000Z","updated":"2020-08-04T15:34:42.820Z","comments":true,"path":"2020/08/04/ClassicConvNet/","link":"","permalink":"https://skylark1001.github.io/2020/08/04/ClassicConvNet/","excerpt":"","text":"经典网络模型本文介绍几个经典的深度网络模型：AlexNet、VGG、ResNet。内容主要包括模型简单介绍、Pytorch官方代码实现。 AlexNetAlexNet是2012年ImageNet竞赛冠军，效果远超第二名。AlexNet是一个8层的网络结构，包括5层卷积层和3个全连接层。现在来看，是一个结构非常简单的网络模型，但在当时获得了惊人的结果。 下面直接来看Pytorch的官方实现：12345678910111213141516171819202122232425262728293031323334353637class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() # 特征提取部分（卷积实现） self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGVGG在模型深度上做了研究，做了16层和19层。VGG是一个非常棒的特征提取网络，后来的多个网络都使用了VGG作为Backbone。 Pytorch官方实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class VGG(nn.Module): def __init__(self, features, num_classes=1000, init_weights=True): super(VGG, self).__init__() self.features = features self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(), nn.Linear(4096, num_classes), ) if init_weights: self._initialize_weights() def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0)def make_layers(cfg, batch_norm=False): layers = [] in_channels = 3 for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] else: conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) if batch_norm: layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] else: layers += [conv2d, nn.ReLU(inplace=True)] in_channels = v return nn.Sequential(*layers)cfgs = &#123; # vgg11 'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # vgg13 'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # vgg 16 'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], # vgg19 'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],&#125;def _vgg(arch, cfg, batch_norm, pretrained, progress, **kwargs): if pretrained: kwargs['init_weights'] = False model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[arch], progress=progress) model.load_state_dict(state_dict) return modeldef vggxx(pretrained=False, progress=True, **kwargs): # cfg 'A' 'B' 'D' 'E' return _vgg('vggxx', 'A', False, pretrained, progress, **kwargs)","categories":[{"name":"Network","slug":"Network","permalink":"https://skylark1001.github.io/categories/Network/"}],"tags":[{"name":"卷积神经网络","slug":"卷积神经网络","permalink":"https://skylark1001.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]}],"categories":[{"name":"Network","slug":"Network","permalink":"https://skylark1001.github.io/categories/Network/"}],"tags":[{"name":"卷积神经网络","slug":"卷积神经网络","permalink":"https://skylark1001.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]}